{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWIF8POHGLrp",
        "outputId": "bda705f8-8757-4ce6-d614-84ee9ea76e01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip -q install torchaudio torch comet-ml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mD4lTHTQGLrt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "\n",
        "def avg_wer(wer_scores, combined_ref_len):\n",
        "    return float(sum(wer_scores)) / float(combined_ref_len)\n",
        "\n",
        "\n",
        "def _levenshtein_distance(ref, hyp):\n",
        "    \"\"\"Levenshtein distance is a string metric for measuring the difference\n",
        "    between two sequences. Informally, the levenshtein disctance is defined as\n",
        "    the minimum number of single-character edits (substitutions, insertions or\n",
        "    deletions) required to change one word into the other. We can naturally\n",
        "    extend the edits to word level when calculate levenshtein disctance for\n",
        "    two sentences.\n",
        "    \"\"\"\n",
        "    m = len(ref)\n",
        "    n = len(hyp)\n",
        "\n",
        "    # special case\n",
        "    if ref == hyp:\n",
        "        return 0\n",
        "    if m == 0:\n",
        "        return n\n",
        "    if n == 0:\n",
        "        return m\n",
        "\n",
        "    if m < n:\n",
        "        ref, hyp = hyp, ref\n",
        "        m, n = n, m\n",
        "\n",
        "    # use O(min(m, n)) space\n",
        "    distance = np.zeros((2, n + 1), dtype=np.int32)\n",
        "\n",
        "    # initialize distance matrix\n",
        "    for j in range(0,n + 1):\n",
        "        distance[0][j] = j\n",
        "\n",
        "    # calculate levenshtein distance\n",
        "    for i in range(1, m + 1):\n",
        "        prev_row_idx = (i - 1) % 2\n",
        "        cur_row_idx = i % 2\n",
        "        distance[cur_row_idx][0] = i\n",
        "        for j in range(1, n + 1):\n",
        "            if ref[i - 1] == hyp[j - 1]:\n",
        "                distance[cur_row_idx][j] = distance[prev_row_idx][j - 1]\n",
        "            else:\n",
        "                s_num = distance[prev_row_idx][j - 1] + 1\n",
        "                i_num = distance[cur_row_idx][j - 1] + 1\n",
        "                d_num = distance[prev_row_idx][j] + 1\n",
        "                distance[cur_row_idx][j] = min(s_num, i_num, d_num)\n",
        "\n",
        "    return distance[m % 2][n]\n",
        "\n",
        "\n",
        "def word_errors(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
        "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
        "    hypothesis sequence in word-level.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param delimiter: Delimiter of input sentences.\n",
        "    :type delimiter: char\n",
        "    :return: Levenshtein distance and word number of reference sentence.\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if ignore_case == True:\n",
        "        reference = reference.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "    ref_words = reference.split(delimiter)\n",
        "    hyp_words = hypothesis.split(delimiter)\n",
        "\n",
        "    edit_distance = _levenshtein_distance(ref_words, hyp_words)\n",
        "    return float(edit_distance), len(ref_words)\n",
        "\n",
        "\n",
        "def char_errors(reference, hypothesis, ignore_case=False, remove_space=False):\n",
        "    \"\"\"Compute the levenshtein distance between reference sequence and\n",
        "    hypothesis sequence in char-level.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param remove_space: Whether remove internal space characters\n",
        "    :type remove_space: bool\n",
        "    :return: Levenshtein distance and length of reference sentence.\n",
        "    :rtype: list\n",
        "    \"\"\"\n",
        "    if ignore_case == True:\n",
        "        reference = reference.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "    join_char = ' '\n",
        "    if remove_space == True:\n",
        "        join_char = ''\n",
        "\n",
        "    reference = join_char.join(filter(None, reference.split(' ')))\n",
        "    hypothesis = join_char.join(filter(None, hypothesis.split(' ')))\n",
        "\n",
        "    edit_distance = _levenshtein_distance(reference, hypothesis)\n",
        "    return float(edit_distance), len(reference)\n",
        "\n",
        "\n",
        "def wer(reference, hypothesis, ignore_case=False, delimiter=' '):\n",
        "    \"\"\"Calculate word error rate (WER). WER compares reference text and\n",
        "    hypothesis text in word-level. WER is defined as:\n",
        "    .. math::\n",
        "        WER = (Sw + Dw + Iw) / Nw\n",
        "    where\n",
        "    .. code-block:: text\n",
        "        Sw is the number of words subsituted,\n",
        "        Dw is the number of words deleted,\n",
        "        Iw is the number of words inserted,\n",
        "        Nw is the number of words in the reference\n",
        "    We can use levenshtein distance to calculate WER. Please draw an attention\n",
        "    that empty items will be removed when splitting sentences by delimiter.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param delimiter: Delimiter of input sentences.\n",
        "    :type delimiter: char\n",
        "    :return: Word error rate.\n",
        "    :rtype: float\n",
        "    :raises ValueError: If word number of reference is zero.\n",
        "    \"\"\"\n",
        "    edit_distance, ref_len = word_errors(reference, hypothesis, ignore_case,\n",
        "                                         delimiter)\n",
        "\n",
        "    if ref_len == 0:\n",
        "        raise ValueError(\"Reference's word number should be greater than 0.\")\n",
        "\n",
        "    wer = float(edit_distance) / ref_len\n",
        "    return wer\n",
        "\n",
        "\n",
        "def cer(reference, hypothesis, ignore_case=False, remove_space=False):\n",
        "    \"\"\"Calculate charactor error rate (CER). CER compares reference text and\n",
        "    hypothesis text in char-level. CER is defined as:\n",
        "    .. math::\n",
        "        CER = (Sc + Dc + Ic) / Nc\n",
        "    where\n",
        "    .. code-block:: text\n",
        "        Sc is the number of characters substituted,\n",
        "        Dc is the number of characters deleted,\n",
        "        Ic is the number of characters inserted\n",
        "        Nc is the number of characters in the reference\n",
        "    We can use levenshtein distance to calculate CER. Chinese input should be\n",
        "    encoded to unicode. Please draw an attention that the leading and tailing\n",
        "    space characters will be truncated and multiple consecutive space\n",
        "    characters in a sentence will be replaced by one space character.\n",
        "    :param reference: The reference sentence.\n",
        "    :type reference: basestring\n",
        "    :param hypothesis: The hypothesis sentence.\n",
        "    :type hypothesis: basestring\n",
        "    :param ignore_case: Whether case-sensitive or not.\n",
        "    :type ignore_case: bool\n",
        "    :param remove_space: Whether remove internal space characters\n",
        "    :type remove_space: bool\n",
        "    :return: Character error rate.\n",
        "    :rtype: float\n",
        "    :raises ValueError: If the reference length is zero.\n",
        "    \"\"\"\n",
        "    edit_distance, ref_len = char_errors(reference, hypothesis, ignore_case,\n",
        "                                         remove_space)\n",
        "\n",
        "    if ref_len == 0:\n",
        "        raise ValueError(\"Length of reference should be greater than 0.\")\n",
        "\n",
        "    cer = float(edit_distance) / ref_len\n",
        "    return cer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uR9RtMrGLrw"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "class TextTransform:\n",
        "    \"\"\"Very simple tokenizer for use with Multilingual Librispeech\n",
        "\n",
        "    Simply checks what characters are in the dataset and uses them as tokens.\n",
        "\n",
        "    Exposes the same interface as tokenizers from the huggingface library, i.e.\n",
        "    encode, decode, decode_batch, get_vocab_size, save, from_file and train.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        char_map_str = \"\"\"\n",
        "        ' 0\n",
        "        <SPACE> 1\n",
        "        a 2\n",
        "        b 3\n",
        "        c 4\n",
        "        d 5\n",
        "        e 6\n",
        "        f 7\n",
        "        g 8\n",
        "        h 9\n",
        "        i 10\n",
        "        j 11\n",
        "        k 12\n",
        "        l 13\n",
        "        m 14\n",
        "        n 15\n",
        "        o 16\n",
        "        p 17\n",
        "        q 18\n",
        "        r 19\n",
        "        s 20\n",
        "        t 21\n",
        "        u 22\n",
        "        v 23\n",
        "        w 24\n",
        "        x 25\n",
        "        y 26\n",
        "        z 27\n",
        "        ö 28\n",
        "        ä 29\n",
        "        ü 30\n",
        "        ß 31\n",
        "        \"\"\"\n",
        "        self.char_map = {}\n",
        "        self.index_map = {}\n",
        "        lines = char_map_str.strip().split(\"\\n\")\n",
        "        for line in lines:\n",
        "          ch,index = line.split()\n",
        "          self.char_map[ch]= int(index)\n",
        "        self.index_map[1]= \" \"\n",
        "    def add_tokens(self, tokens: list[str]):\n",
        "        \"\"\"Manually add tokens to the tokenizer\n",
        "\n",
        "        Args:\n",
        "            tokens (list[str]): List of tokens to add\n",
        "        \"\"\"\n",
        "        for token in tokens:\n",
        "            if token not in self.char_map:\n",
        "                self.char_map[token] = len(self.char_map)\n",
        "                self.index_map[len(self.index_map)] = token\n",
        "\n",
        "    def text_to_int(self, sequence: str):\n",
        "        \"\"\"Use a character map and convert text to an integer sequence\"\"\"\n",
        "        int_sequence = []\n",
        "        for char in sequence:\n",
        "          if char == \" \":\n",
        "            ch = self.char_map[\"<SPACE>\"]\n",
        "          else:\n",
        "            ch = self.char_map[char]\n",
        "          int_sequence.append(ch)\n",
        "        return int_sequence\n",
        "\n",
        "    def int_to_text(self, labels: list[int]):\n",
        "        \"\"\"Use a character map and convert integer labels to an text sequence\n",
        "\n",
        "        Args:\n",
        "            labels (list[int]): List of integer labels\n",
        "            remove_special_tokens (bool): Whether to remove special tokens.\n",
        "                Defaults to True.\n",
        "        \"\"\"\n",
        "        string = []\n",
        "        for i in labels:\n",
        "            string.append(self.index_map[f\"{i}\"])\n",
        "        return \"\".join(string).replace(\"<SPACE>\", \" \")\n",
        "\n",
        "    @staticmethod\n",
        "    def from_file(path: str) -> \"TextTransform\":\n",
        "        \"\"\"Load the tokenizer from a file\"\"\"\n",
        "        char_tokenizer = TextTransform()\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as file:\n",
        "            # load it in the following format:\n",
        "            # {\"char_map\": {\"a\": 0, \"b\": 1, ...}, \"index_map\": {0: \"a\", 1: \"b\", ...}}\n",
        "            saved_file = json.load(file)\n",
        "        char_tokenizer.char_map = saved_file[\"char_map\"]\n",
        "        char_tokenizer.index_map = saved_file[\"index_map\"]\n",
        "\n",
        "        return char_tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wonK1oPOGLrx",
        "outputId": "e97f81e5-ceac-4954-d94f-818cc99a3c65"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "train_audio_transforms = nn.Sequential(\n",
        "    torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_mels=128),\n",
        "    torchaudio.transforms.FrequencyMasking(freq_mask_param=30),\n",
        "    torchaudio.transforms.TimeMasking(time_mask_param=100)\n",
        ")\n",
        "\n",
        "valid_audio_transforms = torchaudio.transforms.MelSpectrogram()\n",
        "\n",
        "text_transform = TextTransform()\n",
        "\n",
        "def data_processing(data, data_type=\"train\"):\n",
        "    spectrograms = []\n",
        "    labels = []\n",
        "    input_lengths = []\n",
        "    label_lengths = []\n",
        "    for (waveform, _, utterance, _, _, _) in data:\n",
        "        if data_type == 'train':\n",
        "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        elif data_type == 'valid':\n",
        "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
        "        else:\n",
        "            raise Exception('data_type should be train or valid')\n",
        "        spectrograms.append(spec)\n",
        "        label = torch.Tensor(text_transform.text_to_int(utterance.lower()))\n",
        "        labels.append(label)\n",
        "        input_lengths.append(spec.shape[0]//2)\n",
        "        label_lengths.append(len(label))\n",
        "\n",
        "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
        "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
        "\n",
        "    return spectrograms, labels, input_lengths, label_lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nK4gSWFEGLry"
      },
      "outputs": [],
      "source": [
        "def GreedyDecoder(output, labels, label_lengths, blank_label=12, collapse_repeated=True):\n",
        "\targ_maxes = torch.argmax(output, dim=2)\n",
        "\tdecodes = []\n",
        "\ttargets = []\n",
        "\tfor i, args in enumerate(arg_maxes):\n",
        "\t\tdecode = []\n",
        "\t\ttargets.append(text_transform.int_to_text(labels[i][:label_lengths[i]].tolist()))\n",
        "\t\tfor j, index in enumerate(args):\n",
        "\t\t\tif index != blank_label:\n",
        "\t\t\t\tif collapse_repeated and j != 0 and index == args[j -1]:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\tdecode.append(index.item())\n",
        "\t\tdecodes.append(text_transform.int_to_text(decode))\n",
        "\treturn decodes, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BF6pO8liGLrz"
      },
      "outputs": [],
      "source": [
        "class CNNLayerNorm(nn.Module):\n",
        "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
        "    def __init__(self, n_feats):\n",
        "        super(CNNLayerNorm, self).__init__()\n",
        "        self.layer_norm = nn.LayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x (batch, channel, feature, time)\n",
        "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
        "        x = self.layer_norm(x)\n",
        "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time)\n",
        "\n",
        "\n",
        "class ResidualCNN(nn.Module):\n",
        "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
        "        except with layer norm instead of batch norm\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
        "        super(ResidualCNN, self).__init__()\n",
        "\n",
        "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
        "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x  # (batch, channel, feature, time)\n",
        "        x = self.layer_norm1(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.cnn1(x)\n",
        "        x = self.layer_norm2(x)\n",
        "        x = F.gelu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.cnn2(x)\n",
        "        x += residual\n",
        "        return x # (batch, channel, feature, time)\n",
        "\n",
        "\n",
        "class BidirectionalGRU(nn.Module):\n",
        "\n",
        "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
        "        super(BidirectionalGRU, self).__init__()\n",
        "\n",
        "        self.BiGRU = nn.GRU(\n",
        "            input_size=rnn_dim, hidden_size=hidden_size,\n",
        "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
        "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_norm(x)\n",
        "        x = F.gelu(x)\n",
        "        x, _ = self.BiGRU(x)\n",
        "        x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SpeechRecognitionModel(nn.Module):\n",
        "\n",
        "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
        "        super(SpeechRecognitionModel, self).__init__()\n",
        "        n_feats = n_feats//2\n",
        "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n",
        "\n",
        "        # n residual cnn layers with filter size of 32\n",
        "        self.rescnn_layers = nn.Sequential(*[\n",
        "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats)\n",
        "            for _ in range(n_cnn_layers)\n",
        "        ])\n",
        "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
        "        self.birnn_layers = nn.Sequential(*[\n",
        "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
        "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
        "            for i in range(n_rnn_layers)\n",
        "        ])\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(rnn_dim*2, rnn_dim),  # birnn returns rnn_dim*2\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(rnn_dim, n_class)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.cnn(x)\n",
        "        x = self.rescnn_layers(x)\n",
        "        sizes = x.size()\n",
        "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
        "        x = x.transpose(1, 2) # (batch, time, feature)\n",
        "        x = self.fully_connected(x)\n",
        "        x = self.birnn_layers(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GneC1L9wGLr0"
      },
      "outputs": [],
      "source": [
        "from enum import Enum\n",
        "from typing import Tuple\n",
        "from torch import Tensor\n",
        "from torchaudio.datasets.utils import _extract_tar\n",
        "\n",
        "\n",
        "class MLSSplit(str, Enum):\n",
        "    \"\"\"Enum specifying dataset as they are defined in the\n",
        "    Multilingual LibriSpeech dataset\"\"\"\n",
        "\n",
        "    TRAIN = \"train\"\n",
        "    TEST = \"test\"\n",
        "    DEV = \"dev\"\n",
        "\n",
        "\n",
        "class Split(str, Enum):\n",
        "    \"\"\"Extending the MLSSplit class to allow for a custom validatio split\"\"\"\n",
        "\n",
        "    TRAIN = \"train\"\n",
        "    VALID = \"valid\"\n",
        "    TEST = \"test\"\n",
        "    DEV = \"dev\"\n",
        "\n",
        "def split_to_mls_split(split_name: Split) -> MLSSplit:\n",
        "    \"\"\"Converts the custom split to a MLSSplit\"\"\"\n",
        "    if split_name == Split.VALID:\n",
        "        return MLSSplit.TRAIN\n",
        "    else:\n",
        "        return split_name  # type: ignore\n",
        "\n",
        "class MLSDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Custom Dataset for reading Multilingual LibriSpeech\n",
        "\n",
        "    Attributes:\n",
        "        dataset_path (str):\n",
        "            path to the dataset\n",
        "        language (str):\n",
        "            language of the dataset\n",
        "        split (Split):\n",
        "            split of the dataset\n",
        "        mls_split (MLSSplit):\n",
        "            split of the dataset as defined in the Multilingual LibriSpeech dataset\n",
        "        dataset_lookup (list):\n",
        "            list of dicts containing the speakerid, bookid, chapterid and utterance\n",
        "\n",
        "    directory structure:\n",
        "        <dataset_path>\n",
        "        ├── <language>\n",
        "        │  ├── train\n",
        "        │  │  ├── transcripts.txt\n",
        "        │  │  └── audio\n",
        "        │  │     └── <speakerid>\n",
        "        │  │        └── <bookid>\n",
        "        │  │           └── <speakerid>_<bookid>_<chapterid>.opus / .flac\n",
        "\n",
        "        each line in transcripts.txt has the following format:\n",
        "        <speakerid>_<bookid>_<chapterid> <utterance>\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        dataset_path: str,\n",
        "        language: str,\n",
        "        split: Split,\n",
        "        limited: bool,\n",
        "        download: bool,\n",
        "    ):\n",
        "        \"\"\"Initializes the dataset\"\"\"\n",
        "        self.dataset_path = dataset_path\n",
        "        self.language = language\n",
        "        self.file_ext = \".opus\" if \"opus\" in language else \".flac\"\n",
        "        self.mls_split: MLSSplit = split_to_mls_split(split)  # split path on disk\n",
        "        self.split: Split = split  # split used internally\n",
        "\n",
        "\n",
        "        self.dataset_lookup = []\n",
        "\n",
        "        self._handle_download_dataset(download)\n",
        "        self._validate_local_directory()\n",
        "        if limited and (split == Split.TRAIN or split == Split.VALID):\n",
        "            self.initialize_limited()\n",
        "        else:\n",
        "            self.initialize()\n",
        "\n",
        "    def initialize_limited(self) -> None:\n",
        "        \"\"\"Initializes the limited supervision dataset\"\"\"\n",
        "        # get file handles\n",
        "        # get file paths\n",
        "        # get transcripts\n",
        "        # create train or validation split\n",
        "\n",
        "        handles = set()\n",
        "\n",
        "        train_root_path = os.path.join(self.dataset_path, self.language, \"train\")\n",
        "\n",
        "        # get file handles for 9h\n",
        "        with open(\n",
        "            os.path.join(train_root_path, \"limited_supervision\", \"9hr\", \"handles.txt\"),\n",
        "            \"r\",\n",
        "            encoding=\"utf-8\",\n",
        "        ) as file:\n",
        "            for line in file:\n",
        "                handles.add(line.strip())\n",
        "\n",
        "        # get file handles for 1h splits\n",
        "        for handle_path in os.listdir(os.path.join(train_root_path, \"limited_supervision\", \"1hr\")):\n",
        "            if handle_path not in range(0, 6):\n",
        "                continue\n",
        "            with open(\n",
        "                os.path.join(\n",
        "                    train_root_path, \"limited_supervision\", \"1hr\", handle_path, \"handles.txt\"\n",
        "                ),\n",
        "                \"r\",\n",
        "                encoding=\"utf-8\",\n",
        "            ) as file:\n",
        "                for line in file:\n",
        "                    handles.add(line.strip())\n",
        "\n",
        "        # get file paths for handles\n",
        "        file_paths = []\n",
        "        for handle in handles:\n",
        "            file_paths.append(\n",
        "                os.path.join(\n",
        "                    train_root_path,\n",
        "                    \"audio\",\n",
        "                    handle.split(\"_\")[0],\n",
        "                    handle.split(\"_\")[1],\n",
        "                    handle + self.file_ext,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # get transcripts for handles\n",
        "        transcripts = []\n",
        "        with open(os.path.join(train_root_path, \"transcripts.txt\"), \"r\", encoding=\"utf-8\") as file:\n",
        "            for line in file:\n",
        "                if line.split(\"\\t\")[0] in handles:\n",
        "                    transcripts.append(line.strip())\n",
        "\n",
        "        # create train or valid split randomly with seed 42\n",
        "        if self.split == Split.TRAIN:\n",
        "            np.random.seed(42)\n",
        "            indices = np.random.choice(len(file_paths), int(len(file_paths) * 0.8))\n",
        "            file_paths = [file_paths[i] for i in indices]\n",
        "            transcripts = [transcripts[i] for i in indices]\n",
        "        elif self.split == Split.VALID:\n",
        "            np.random.seed(42)\n",
        "            indices = np.random.choice(len(file_paths), int(len(file_paths) * 0.2))\n",
        "            file_paths = [file_paths[i] for i in indices]\n",
        "            transcripts = [transcripts[i] for i in indices]\n",
        "\n",
        "        # create dataset lookup\n",
        "        self.dataset_lookup = [\n",
        "            {\n",
        "                \"speakerid\": path.split(\"/\")[-3],\n",
        "                \"bookid\": path.split(\"/\")[-2],\n",
        "                \"chapterid\": path.split(\"/\")[-1].split(\"_\")[2].split(\".\")[0],\n",
        "                \"utterance\": utterance.split(\"\\t\")[1],\n",
        "            }\n",
        "            for path, utterance in zip(file_paths, transcripts, strict=False)\n",
        "        ]\n",
        "\n",
        "    def initialize(self) -> None:\n",
        "\n",
        "        \"\"\"Initializes the entire dataset\n",
        "\n",
        "        Reads the transcripts.txt file and creates a lookup table\n",
        "        \"\"\"\n",
        "        transcripts_path = os.path.join(\n",
        "            self.dataset_path, self.language, self.mls_split, \"transcripts.txt\"\n",
        "        )\n",
        "\n",
        "        with open(transcripts_path, \"r\", encoding=\"utf-8\") as script_file:\n",
        "            # read all lines in transcripts.txt\n",
        "            transcripts = script_file.readlines()\n",
        "            # split each line into (<speakerid>_<bookid>_<chapterid>, <utterance>)\n",
        "            transcripts = [line.strip().split(\"\\t\", 1) for line in transcripts]  # type: ignore\n",
        "            utterances = [utterance.strip() for _, utterance in transcripts]  # type: ignore\n",
        "            identifier = [identifier.strip() for identifier, _ in transcripts]  # type: ignore\n",
        "            identifier = [path.split(\"_\") for path in identifier]\n",
        "\n",
        "            if self.split == Split.VALID:\n",
        "                np.random.seed(42)\n",
        "                indices = np.random.choice(len(utterances), int(len(utterances) * 0.2))\n",
        "                utterances = [utterances[i] for i in indices]\n",
        "                identifier = [identifier[i] for i in indices]\n",
        "            elif self.split == Split.TRAIN:\n",
        "                np.random.seed(42)\n",
        "                indices = np.random.choice(len(utterances), int(len(utterances) * 0.8))\n",
        "                utterances = [utterances[i] for i in indices]\n",
        "                identifier = [identifier[i] for i in indices]\n",
        "\n",
        "            self.dataset_lookup = [\n",
        "                {\n",
        "                    \"speakerid\": path[0],\n",
        "                    \"bookid\": path[1],\n",
        "                    \"chapterid\": path[2],\n",
        "                    \"utterance\": utterance,\n",
        "                }\n",
        "                for path, utterance in zip(identifier, utterances, strict=False)\n",
        "            ]\n",
        "    def _handle_download_dataset(self, download: bool) -> None:\n",
        "        \"\"\"Download the dataset\"\"\"\n",
        "        if not download:\n",
        "            print(\"Download flag not set, skipping download\")\n",
        "            return\n",
        "        # zip exists:\n",
        "        if os.path.isfile(os.path.join(self.dataset_path, self.language) + \".tar.gz\") and download:\n",
        "            print(f\"Found dataset at {self.dataset_path}. Skipping download\")\n",
        "        # zip does not exist:\n",
        "        else:\n",
        "            os.makedirs(self.dataset_path, exist_ok=True)\n",
        "            url = f\"https://dl.fbaipublicfiles.com/mls/{self.language}.tar.gz\"\n",
        "\n",
        "            torch.hub.download_url_to_file(\n",
        "                url, os.path.join(self.dataset_path, self.language) + \".tar.gz\"\n",
        "            )\n",
        "\n",
        "        # unzip the dataset\n",
        "        if not os.path.isdir(os.path.join(self.dataset_path, self.language)):\n",
        "            print(\n",
        "                f\"Unzipping the dataset at \\\n",
        "                    {os.path.join(self.dataset_path, self.language) + '.tar.gz'}\"\n",
        "            )\n",
        "            _extract_tar(\n",
        "                os.path.join(self.dataset_path, self.language) + \".tar.gz\", overwrite=True\n",
        "            )\n",
        "        else:\n",
        "            print(\"Dataset is already unzipped, validating it now\")\n",
        "            return\n",
        "\n",
        "    def _validate_local_directory(self):\n",
        "        # check if dataset_path exists\n",
        "        if not os.path.exists(self.dataset_path):\n",
        "            raise ValueError(\"Dataset path does not exist\")\n",
        "        if not os.path.exists(os.path.join(self.dataset_path, self.language)):\n",
        "            raise ValueError(\"Language not downloaded!\")\n",
        "        if not os.path.exists(os.path.join(self.dataset_path, self.language, self.mls_split)):\n",
        "            raise ValueError(\"Split not found in dataset\")\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Returns the length of the dataset\"\"\"\n",
        "        return len(self.dataset_lookup)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[Tensor, int, str, int, int, int]:\n",
        "        \"\"\"One sample\n",
        "\n",
        "        Returns:\n",
        "            Tuple of the following items;\n",
        "\n",
        "            Tensor:\n",
        "                Waveform\n",
        "            int:\n",
        "                Sample rate\n",
        "            str:\n",
        "                Transcript\n",
        "            int:\n",
        "                Speaker ID\n",
        "            int:\n",
        "                Chapter ID\n",
        "            int:\n",
        "                Utterance ID\n",
        "        \"\"\"\n",
        "        # get the utterance\n",
        "        dataset_lookup_entry = self.dataset_lookup[idx]\n",
        "\n",
        "        utterance = dataset_lookup_entry[\"utterance\"]\n",
        "\n",
        "        # get the audio file\n",
        "        audio_path = os.path.join(\n",
        "            self.dataset_path,\n",
        "            self.language,\n",
        "            self.mls_split,\n",
        "            \"audio\",\n",
        "            self.dataset_lookup[idx][\"speakerid\"],\n",
        "            self.dataset_lookup[idx][\"bookid\"],\n",
        "            \"_\".join(\n",
        "                [\n",
        "                    self.dataset_lookup[idx][\"speakerid\"],\n",
        "                    self.dataset_lookup[idx][\"bookid\"],\n",
        "                    self.dataset_lookup[idx][\"chapterid\"],\n",
        "                ]\n",
        "            )\n",
        "            + self.file_ext,\n",
        "        )\n",
        "\n",
        "        waveform, sample_rate = torchaudio.load(audio_path)  # pylint: disable=no-member\n",
        "\n",
        "        # resample if necessary\n",
        "        if sample_rate != 16000:\n",
        "            resampler = torchaudio.transforms.Resample(\n",
        "                sample_rate, 16000\n",
        "            )\n",
        "            waveform = resampler(waveform)\n",
        "\n",
        "\n",
        "        return (\n",
        "            waveform,\n",
        "            sample_rate,\n",
        "            utterance,\n",
        "            dataset_lookup_entry[\"speakerid\"],\n",
        "            dataset_lookup_entry[\"chapterid\"],\n",
        "            idx,\n",
        "        )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYd7mwE9GLr1"
      },
      "outputs": [],
      "source": [
        "class IterMeter(object):\n",
        "    \"\"\"keeps track of total iterations\"\"\"\n",
        "    def __init__(self):\n",
        "        self.val = 0\n",
        "\n",
        "    def step(self):\n",
        "        self.val += 1\n",
        "\n",
        "    def get(self):\n",
        "        return self.val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCpxXfrQGLr2"
      },
      "outputs": [],
      "source": [
        "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter):\n",
        "    model.train()\n",
        "    data_len = len(train_loader.dataset)\n",
        "    for batch_idx, _data in enumerate(train_loader):\n",
        "        spectrograms, labels, input_lengths, label_lengths = _data\n",
        "        spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(spectrograms)  # (batch, time, n_class)\n",
        "        output = F.log_softmax(output, dim=2)\n",
        "        output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "\n",
        "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        iter_meter.step()\n",
        "        if batch_idx % 100 == 0 or batch_idx == data_len:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(spectrograms), data_len,\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, criterion, epoch, iter_meter):\n",
        "    print('\\nevaluating...')\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_cer, test_wer = [], []\n",
        "    with torch.no_grad():\n",
        "        for i, _data in enumerate(test_loader):\n",
        "            spectrograms, labels, input_lengths, label_lengths = _data\n",
        "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
        "\n",
        "            output = model(spectrograms)  # (batch, time, n_class)\n",
        "            output = F.log_softmax(output, dim=2)\n",
        "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
        "\n",
        "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
        "            test_loss += loss.item() / len(test_loader)\n",
        "\n",
        "            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
        "            for j in range(len(decoded_preds)):\n",
        "                test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
        "                test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
        "\n",
        "\n",
        "    avg_cer = sum(test_cer)/len(test_cer)\n",
        "    avg_wer = sum(test_wer)/len(test_wer)\n",
        "\n",
        "    print('Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(test_loss, avg_cer, avg_wer))\n",
        "\n",
        "\n",
        "def main(learning_rate=5e-4, batch_size=20, epochs=10):\n",
        "\n",
        "    hparams = {\n",
        "        \"n_cnn_layers\": 3,\n",
        "        \"n_rnn_layers\": 5,\n",
        "        \"rnn_dim\": 512,\n",
        "        \"n_class\": 29,\n",
        "        \"n_feats\": 128,\n",
        "        \"stride\":2,\n",
        "        \"dropout\": 0.1,\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"epochs\": epochs\n",
        "    }\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    torch.manual_seed(7)\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if not os.path.isdir(\"./data\"):\n",
        "        os.makedirs(\"./data\")\n",
        "\n",
        "    train_dataset = MLSDataset(\"./data\", \"mls_german_opus\", Split.TRAIN, True, False)\n",
        "    test_dataset = MLSDataset(\"./data\", \"mls_german_opus\", Split.VALID, True, False)\n",
        "\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "    train_loader = data.DataLoader(dataset=train_dataset,\n",
        "                                batch_size=hparams['batch_size'],\n",
        "                                shuffle=True,\n",
        "                                collate_fn=lambda x: data_processing(x, 'train'),\n",
        "                                **kwargs)\n",
        "    test_loader = data.DataLoader(dataset=test_dataset,\n",
        "                                batch_size=hparams['batch_size'],\n",
        "                                shuffle=False,\n",
        "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
        "                                **kwargs)\n",
        "\n",
        "    model = SpeechRecognitionModel(\n",
        "        hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
        "        hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
        "        ).to(device)\n",
        "\n",
        "    print(model)\n",
        "    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
        "\n",
        "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
        "    criterion = nn.CTCLoss(blank=28).to(device)\n",
        "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'],\n",
        "                                            steps_per_epoch=int(len(train_loader)),\n",
        "                                            epochs=hparams['epochs'],\n",
        "                                            anneal_strategy='linear')\n",
        "\n",
        "    iter_meter = IterMeter()\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter)\n",
        "        test(model, device, test_loader, criterion, epoch, iter_meter)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "kNfg53CsGLr3",
        "outputId": "b2cbbe83-7c1c-42e7-db91-4cd4ab5797a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Download flag not set, skipping download\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-6f2251599afe>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-5656b7485d9f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(learning_rate, batch_size, epochs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLSDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mls_german_opus\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLSDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mls_german_opus\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVALID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-78a3fe869f29>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset_path, language, split, limited, download)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_download_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_local_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlimited\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVALID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_limited\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-78a3fe869f29>\u001b[0m in \u001b[0;36m_validate_local_directory\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset path does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Language not downloaded!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmls_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Split not found in dataset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Language not downloaded!"
          ]
        }
      ],
      "source": [
        "learning_rate = 5e-4\n",
        "batch_size = 10\n",
        "epochs = 10\n",
        "\n",
        "main(learning_rate, batch_size, epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNrAM5IaGLr4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
